# -*- coding: utf-8 -*-
"""RAG-Multi-Agent-System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BbhCfvGS4AT28gDCKei2foZ716cXFn
"""

# -----------------------------
# 1. Environment Setup
# -----------------------------
from google.colab import userdata
import os

os.environ["GROQ_API_KEY"] = userdata.get("groq_api_key")

# -----------------------------
# 2. Install Required Packages
# -----------------------------
!pip install -qU "langchain[groq]"
!pip install -qU langchain-huggingface
!pip install -qU sentence-transformers
!pip install -qU datasets transformers
!pip install -qU langchain-chroma
!pip install -qU langchain-community
!pip install -qU bs4

# -----------------------------
# 3. Load Chat Model from Groq
# -----------------------------
from langchain.chat_models import init_chat_model

model = init_chat_model("openai/gpt-oss-20b", model_provider="groq")

# -----------------------------
# 4. Set Up Embeddings
# -----------------------------
from langchain_huggingface import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-mpnet-base-v2"
)

# -----------------------------
# 5. Set Up Vector Store (Chroma)
# -----------------------------
from langchain_chroma import Chroma

vector_store = Chroma(
    collection_name="example_collection",
    embedding_function=embeddings,
    persist_directory="./chroma_langchain_db",
)

# Install pypdf
!pip install -qU pypdf

# Load multiple web pages
web_loader = WebBaseLoader(
    web_paths=[
        "https://www.abcd.com/think/topics/convolutional-neural-networks",
        "https://www.abcd.gov.in/en/personal_life_story/personal-life-story/"
    ]
)
web_docs = web_loader.load()

# -----------------------------
# Load PDF Files
# -----------------------------
# Load single or multiple PDFs
pdf_loader1 = PyPDFLoader("/content/Siddarth.pdf")
pdf_docs = pdf_loader1.load()

# -----------------------------
# Combine All Docs
# -----------------------------
all_docs = web_docs + pdf_docs

# -----------------------------
# Split and Add to Vector DB
# -----------------------------
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
all_splits = text_splitter.split_documents(all_docs)

# Add chunks to vector store
_ = vector_store.add_documents(documents=all_splits)

# -----------------------------
# 7. Create Retriever
# -----------------------------
retriever = vector_store.as_retriever()

# -----------------------------
# 8. Define Prompt Template
# -----------------------------
from langchain_core.prompts import ChatPromptTemplate

template = """Answer the question based only on the following context:
{context}

Question: {input}
"""

prompt = ChatPromptTemplate.from_template(template)

# -----------------------------
# 9. Build RAG Chain
# -----------------------------
from langchain_core.runnables import RunnablePassthrough, RunnableParallel

rag_chain = (
    RunnableParallel(
        {"context": retriever, "input": RunnablePassthrough()}
    )
    | prompt
    | model
)

response = rag_chain.invoke("give me the projects information?")
print(response.content)

